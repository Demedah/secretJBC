# -*- coding: utf-8 -*-
"""Uji Coba Citra FIX

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zeJOCpU6Ruy_drFkAEQq1xMBhY1Y2nAh
"""

!pip install opencv-python

"""## Import Library"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from skimage.feature import graycomatrix, graycoprops
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""## Mount Data"""

#1. mount google
from google.colab import drive
drive.mount('/content/drive')

"""## Ekstraksi Fitur"""

def ekstrak_fitur_gambar(img_input):
    try:
        # Cek tipe input
        if isinstance(img_input, str):
            img = cv2.imread(img_input)
            if img is None:
                print(f"Error: Gambar tidak dapat dibaca dari path: {img_input}")
                return None
        elif isinstance(img_input, np.ndarray):
            img = img_input
        else:
            print("Error: Input harus berupa path string atau numpy array gambar.") #takut lupa
            return None

        # Resize agar konsisten
        if img.shape[0] != 128 or img.shape[1] != 128:
            img = cv2.resize(img, (128, 128))

        # Konversi ke grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # ===== GLCM (Tekstur) =====
        glcm = graycomatrix(gray, distances=[1], angles=[0], symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast')[0, 0]
        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]
        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
        energy = graycoprops(glcm, 'energy')[0, 0]
        correlation = graycoprops(glcm, 'correlation')[0, 0]

        # ===== Histogram Warna =====
        hist_b = cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()
        hist_g = cv2.calcHist([img], [1], None, [256], [0, 256]).flatten()
        hist_r = cv2.calcHist([img], [2], None, [256], [0, 256]).flatten()

        # Normalisasi histogram
        hist_b = hist_b / hist_b.sum() if hist_b.sum() != 0 else hist_b
        hist_g = hist_g / hist_g.sum() if hist_g.sum() != 0 else hist_g
        hist_r = hist_r / hist_r.sum() if hist_r.sum() != 0 else hist_r
        # Debugging: Print jumlah dari histograms
       # print(f"Debug: jumlah histograms: B={hist_b.sum()}, G={hist_g.sum()}, R={hist_r.sum()}")

        fitur_hist = np.hstack([hist_b, hist_g, hist_r])

        # Gabung semua fitur
        fitur = np.hstack([contrast, dissimilarity, homogeneity, energy, correlation, fitur_hist])
        return fitur
    except Exception as e:
        print(f"Error ekstrak fitur: {e}")
        return None

"""## Load Data"""

# ====== 1) Path Dataset ======
csv_path = "/content/drive/MyDrive/A Skripsi/CSV/databaseJBC.csv"
image_dir = "/content/drive/MyDrive/A Skripsi/Extraksi"

df = pd.read_csv(csv_path)

X = []
y = []

for idx, row in df.iterrows():
    if pd.isna(row["FotoCS"]):
        print(f"Nama File tidak valid pada indeks {idx}.")
        continue

    img_path = os.path.join(image_dir, row["FotoCS"])
    if os.path.exists(img_path):
        fitur = ekstrak_fitur_gambar(img_path)  # lewat img_path daripada img
        if fitur is not None:
            X.append(fitur)
            y.append(row["Tekstur Kulit"])
    else:
        print(f"File tidak ditemukan: {img_path}") # Print the constructed path to help debugging
X = np.array(X)
y = np.array(y)
print(f"Jumlah data asli: {len(X)}")

df = pd.read_csv(csv_path)
print(df.head())

"""## Split Data & Latih Model Sebelum Augmentasi"""

if len(X) == 0:
    print("Error: tidak ada data, cek lagi.")
else:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #Dibagi datanya

    model_before = RandomForestClassifier(n_estimators=100, random_state=42)
    model_before.fit(X_train, y_train)
    y_pred_before = model_before.predict(X_test)
    acc_before = accuracy_score(y_test, y_pred_before)

    print("Akurasi Sebelum Augmentasi:", acc_before)

    print("\n=== Classification Report (Sebelum Augmentasi) ===")
    print(classification_report(y_test, y_pred_before))

    cm_before = confusion_matrix(y_test, y_pred_before)
    sns.heatmap(cm_before, annot=True, fmt="d", cmap="Blues")
    plt.title("Confusion Matrix - Sebelum Augmentasi")
    plt.xlabel("Predicted")
    plt.ylabel("Actual") # missing ylabel
    plt.show()

"""
## Data Augmentasi
karena akurasi sangat rendah, jadi kita augmentasi dengan  transformasi seperti rotasi sebesar 15Â°, pergeseran horizontal dan vertikal sebesar 10%, zoom 10%, dan pembalikan horizontal."""

datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True
)

X_aug = []
y_aug = []

for idx, row in df.iterrows():
    img_path = os.path.join(image_dir, row["FotoCS"])
    if os.path.exists(img_path):
        img = cv2.imread(img_path)
        if img is None:
            print(f"Peringatan: Tidak dapat membaca file gambar pada {img_path}")
            continue
        img = cv2.resize(img, (128, 128))
        img = np.expand_dims(img, 0)  # Tambah dimensi batch

        # Generate beberapa gambar augmentasi
        aug_iter = datagen.flow(img, batch_size=1)
        for _ in range(2):  # jumlah augmentasi per gambar
            aug_img = next(aug_iter)[0].astype(np.uint8)
            fitur = ekstrak_fitur_gambar(aug_img)
            if fitur is not None:
                X_aug.append(fitur)
                y_aug.append(row["Tekstur Kulit"])
        else:
             # Original image features
             fitur = ekstrak_fitur_gambar(img[0]) # Extract features dari original image
             if fitur is not None:
                X_aug.append(fitur)
                y_aug.append(row["Tekstur Kulit"])




# Gabungkan data asli + augmentasi
X_total = np.vstack([X, X_aug])
y_total = np.hstack([y, y_aug])

print(f"Jumlah data setelah augmentasi: {len(X_total)}")

"""##Latih Model Sesudah Augmentasi"""

X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(
    X_total, y_total, test_size=0.2, random_state=42
)

model_after = RandomForestClassifier(n_estimators=100, random_state=42)
model_after.fit(X_train_aug, y_train_aug)
y_pred_after = model_after.predict(X_test_aug)
acc_after = accuracy_score(y_test_aug, y_pred_after)

print("Akurasi Setelah Augmentasi:", acc_after)

print("\n=== Classification Report (Setelah Augmentasi) ===")
print(classification_report(y_test_aug, y_pred_after))

cm_after = confusion_matrix(y_test_aug, y_pred_after)
sns.heatmap(cm_after, annot=True, fmt="d", cmap="Greens")
plt.title("Confusion Matrix - Setelah Augmentasi")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""## Visualisasi Perbandingan Akurasi"""

acc_values = [acc_before, acc_after]
labels = ["Sebelum", "Sesudah"]
colors = ["red", "green"]

plt.bar(labels, acc_values, color=colors)
plt.ylabel("Akurasi")
plt.title("Perbandingan Akurasi Sebelum & Sesudah Augmentasi")
plt.ylim(0, 1)

# Angka persentasenya
for i, v in enumerate(acc_values):
    plt.text(i, v + 0.02, f"{v*100:.2f}%", ha='center', fontweight='bold')

plt.show()

"""## Simpan Akurasi"""

accuracy_results = {
    "Tanpa Augmentasi": acc_before,
    "Dengan Augmentasi": acc_after
}

print("\nSaved Accuracy Results:")
print(accuracy_results)

"""## Uji coba dengan citra baru"""

# UJi COBA 1
from google.colab import files
import os
import cv2
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Pastikan LabelEncoder sudah diinisialisasi dan di-fit dengan semua label yang ada
# Lakukan fitting encoder dengan semua label unik dari data pelatihan
le = LabelEncoder()
le.fit(y_total)

print(f"UPLOAD FOTO ANDA DISINI")
print(f"UNTUK MENENTUKAN JENIS KULIT: {np.unique(y_total)}")

uploaded = files.upload()

for fn in uploaded.keys():
    print(f'\nUser mengunggah file "{fn}" ({len(uploaded[fn])} bytes)')

    # Simpan file yang diunggah ke lokasi sementara
    temp_new_image_path = f"/tmp/{fn}"
    with open(temp_new_image_path, 'wb') as f:
        f.write(uploaded[fn])

    # Ekstrak fitur dari foto baru
    # Gunakan fungsi yang menerima path sebagai input
    new_image_features = ekstrak_fitur_gambar(temp_new_image_path)

    # Hapus file sementara
    os.remove(temp_new_image_path)

    if new_image_features is not None:
        # Ubah bentuk fitur agar sesuai dengan input model (1 sampel, banyak fitur)
        new_image_features = new_image_features.reshape(1, -1)

        # Prediksi label menggunakan model_after (model setelah augmentasi)
        # RandomForestClassifier.predict() langsung mengembalikan label kelas yang diprediksi (string)
        predicted_label = model_after.predict(new_image_features)[0]  # Ambil satu label prediksi

        # Prediksi probabilitas
        prediction_probabilities = model_after.predict_proba(new_image_features)[0]

        print(f"Hasil prediksi jenis kulit: **{predicted_label}**")  # Gunakan label prediksi langsung
        print("Probabilitas:")
        # Urutkan probabilitas berdasarkan nama kelas agar output konsisten
        sorted_classes = sorted(zip(le.classes_, prediction_probabilities), key=lambda x: x[0])
        for class_name, prob in sorted_classes:
             print(f"- {class_name}: {prob:.2f}")

    else:
        print(f"Gagal mengekstrak fitur dari foto '{fn}'. Pastikan file adalah gambar yang valid.")

# UJi COBA 2
from google.colab import files
import os
import cv2
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Pastikan LabelEncoder sudah diinisialisasi dan di-fit dengan semua label yang ada
# Lakukan fitting encoder dengan semua label unik dari data pelatihan
le = LabelEncoder()
le.fit(y_total)

print(f"UPLOAD FOTO ANDA DISINI")
print(f"UNTUK MENENTUKAN JENIS KULIT: {np.unique(y_total)}")

uploaded = files.upload()

for fn in uploaded.keys():
    print(f'\nUser mengunggah file "{fn}" ({len(uploaded[fn])} bytes)')

    # Simpan file yang diunggah ke lokasi sementara
    temp_new_image_path = f"/tmp/{fn}"
    with open(temp_new_image_path, 'wb') as f:
        f.write(uploaded[fn])

    # Ekstrak fitur dari foto baru
    # Gunakan fungsi yang menerima path sebagai input
    new_image_features = ekstrak_fitur_gambar(temp_new_image_path)

    # Hapus file sementara
    os.remove(temp_new_image_path)

    if new_image_features is not None:
        # Ubah bentuk fitur agar sesuai dengan input model (1 sampel, banyak fitur)
        new_image_features = new_image_features.reshape(1, -1)

        # Prediksi label menggunakan model_after (model setelah augmentasi)
        # RandomForestClassifier.predict() langsung mengembalikan label kelas yang diprediksi (string)
        predicted_label = model_after.predict(new_image_features)[0]  # Ambil satu label prediksi

        # Prediksi probabilitas
        prediction_probabilities = model_after.predict_proba(new_image_features)[0]

        print(f"Hasil prediksi jenis kulit: **{predicted_label}**")  # Gunakan label prediksi langsung
        print("Probabilitas:")
        # Urutkan probabilitas berdasarkan nama kelas agar output konsisten
        sorted_classes = sorted(zip(le.classes_, prediction_probabilities), key=lambda x: x[0])
        for class_name, prob in sorted_classes:
             print(f"- {class_name}: {prob:.2f}")

    else:
        print(f"Gagal mengekstrak fitur dari foto '{fn}'. Pastikan file adalah gambar yang valid.")

# UJi COBA 3
from google.colab import files
import os
import cv2
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Pastikan LabelEncoder sudah diinisialisasi dan di-fit dengan semua label yang ada
# Lakukan fitting encoder dengan semua label unik dari data pelatihan
le = LabelEncoder()
le.fit(y_total)

print(f"UPLOAD FOTO ANDA DISINI")
print(f"UNTUK MENENTUKAN JENIS KULIT: {np.unique(y_total)}")

uploaded = files.upload()

for fn in uploaded.keys():
    print(f'\nUser mengunggah file "{fn}" ({len(uploaded[fn])} bytes)')

    # Simpan file yang diunggah ke lokasi sementara
    temp_new_image_path = f"/tmp/{fn}"
    with open(temp_new_image_path, 'wb') as f:
        f.write(uploaded[fn])

    # Ekstrak fitur dari foto baru
    # Gunakan fungsi yang menerima path sebagai input
    new_image_features = ekstrak_fitur_gambar(temp_new_image_path)

    # Hapus file sementara
    os.remove(temp_new_image_path)

    if new_image_features is not None:
        # Ubah bentuk fitur agar sesuai dengan input model (1 sampel, banyak fitur)
        new_image_features = new_image_features.reshape(1, -1)

        # Prediksi label menggunakan model_after (model setelah augmentasi)
        # RandomForestClassifier.predict() langsung mengembalikan label kelas yang diprediksi (string)
        predicted_label = model_after.predict(new_image_features)[0]  # Ambil satu label prediksi

        # Prediksi probabilitas
        prediction_probabilities = model_after.predict_proba(new_image_features)[0]

        print(f"Hasil prediksi jenis kulit: **{predicted_label}**")  # Gunakan label prediksi langsung
        print("Probabilitas:")
        # Urutkan probabilitas berdasarkan nama kelas agar output konsisten
        sorted_classes = sorted(zip(le.classes_, prediction_probabilities), key=lambda x: x[0])
        for class_name, prob in sorted_classes:
             print(f"- {class_name}: {prob:.2f}")

    else:
        print(f"Gagal mengekstrak fitur dari foto '{fn}'. Pastikan file adalah gambar yang valid.")

# UJi COBA 4
from google.colab import files
import os
import cv2
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Pastikan LabelEncoder sudah diinisialisasi dan di-fit dengan semua label yang ada
# Lakukan fitting encoder dengan semua label unik dari data pelatihan
le = LabelEncoder()
le.fit(y_total)

print(f"UPLOAD FOTO ANDA DISINI")
print(f"UNTUK MENENTUKAN JENIS KULIT: {np.unique(y_total)}")

uploaded = files.upload()

for fn in uploaded.keys():
    print(f'\nUser mengunggah file "{fn}" ({len(uploaded[fn])} bytes)')

    # Simpan file yang diunggah ke lokasi sementara
    temp_new_image_path = f"/tmp/{fn}"
    with open(temp_new_image_path, 'wb') as f:
        f.write(uploaded[fn])

    # Ekstrak fitur dari foto baru
    # Gunakan fungsi yang menerima path sebagai input
    new_image_features = ekstrak_fitur_gambar(temp_new_image_path)

    # Hapus file sementara
    os.remove(temp_new_image_path)

    if new_image_features is not None:
        # Ubah bentuk fitur agar sesuai dengan input model (1 sampel, banyak fitur)
        new_image_features = new_image_features.reshape(1, -1)

        # Prediksi label menggunakan model_after (model setelah augmentasi)
        # RandomForestClassifier.predict() langsung mengembalikan label kelas yang diprediksi (string)
        predicted_label = model_after.predict(new_image_features)[0]  # Ambil satu label prediksi

        # Prediksi probabilitas
        prediction_probabilities = model_after.predict_proba(new_image_features)[0]

        print(f"Hasil prediksi jenis kulit: **{predicted_label}**")  # Gunakan label prediksi langsung
        print("Probabilitas:")
        # Urutkan probabilitas berdasarkan nama kelas agar output konsisten
        sorted_classes = sorted(zip(le.classes_, prediction_probabilities), key=lambda x: x[0])
        for class_name, prob in sorted_classes:
             print(f"- {class_name}: {prob:.2f}")

    else:
        print(f"Gagal mengekstrak fitur dari foto '{fn}'. Pastikan file adalah gambar yang valid.")

# UJi COBA 5
from google.colab import files
import os
import cv2
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Pastikan LabelEncoder sudah diinisialisasi dan di-fit dengan semua label yang ada
# Lakukan fitting encoder dengan semua label unik dari data pelatihan
le = LabelEncoder()
le.fit(y_total)

print(f"UPLOAD FOTO ANDA DISINI")
print(f"UNTUK MENENTUKAN JENIS KULIT: {np.unique(y_total)}")

uploaded = files.upload()

for fn in uploaded.keys():
    print(f'\nUser mengunggah file "{fn}" ({len(uploaded[fn])} bytes)')

    # Simpan file yang diunggah ke lokasi sementara
    temp_new_image_path = f"/tmp/{fn}"
    with open(temp_new_image_path, 'wb') as f:
        f.write(uploaded[fn])

    # Ekstrak fitur dari foto baru
    # Gunakan fungsi yang menerima path sebagai input
    new_image_features = ekstrak_fitur_gambar(temp_new_image_path)

    # Hapus file sementara
    os.remove(temp_new_image_path)

    if new_image_features is not None:
        # Ubah bentuk fitur agar sesuai dengan input model (1 sampel, banyak fitur)
        new_image_features = new_image_features.reshape(1, -1)

        # Prediksi label menggunakan model_after (model setelah augmentasi)
        # RandomForestClassifier.predict() langsung mengembalikan label kelas yang diprediksi (string)
        predicted_label = model_after.predict(new_image_features)[0]  # Ambil satu label prediksi

        # Prediksi probabilitas
        prediction_probabilities = model_after.predict_proba(new_image_features)[0]

        print(f"Hasil prediksi jenis kulit: **{predicted_label}**")  # Gunakan label prediksi langsung
        print("Probabilitas:")
        # Urutkan probabilitas berdasarkan nama kelas agar output konsisten
        sorted_classes = sorted(zip(le.classes_, prediction_probabilities), key=lambda x: x[0])
        for class_name, prob in sorted_classes:
             print(f"- {class_name}: {prob:.2f}")

    else:
        print(f"Gagal mengekstrak fitur dari foto '{fn}'. Pastikan file adalah gambar yang valid.")